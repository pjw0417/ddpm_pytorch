{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780588ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Mount Google Drive (Colab)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Install dependencies\n",
    "%pip install -r /content/drive/MyDrive/ddpm_pytorch/requirements.txt\n",
    "\n",
    "import os, sys\n",
    "drive_path = \"/content/drive/MyDrive/ddpm_pytorch\"\n",
    "if os.path.exists(drive_path):\n",
    "    os.chdir(drive_path)\n",
    "    print(\"Changed dir:\", os.getcwd())\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{drive_path} not found\")\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "print(\"Added to sys.path:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8008467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Data using CIFAR10\n",
    "# ---------------------------------\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "from models.unet import UNet\n",
    "from diffusion.gaussian_diffusion import GaussianDiffusion\n",
    "from ema_pytorch import EMA  \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "image_size = 32\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "pin_memory = True\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((image_size, image_size)),\n",
    "    T.RandomHorizontalFlip(),   \n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "test_ds = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(train_ds))\n",
    "print(\"Test:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Model / Diffusion / Optimizer\n",
    "# ---------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet(\n",
    "    dim=128,\n",
    "    dim_mults=(1, 2, 4, 8),\n",
    "    image_size=image_size,\n",
    "    dropout=0.1,\n",
    "    channels=3,\n",
    ").to(device)\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model=model,\n",
    "    image_size=image_size,\n",
    "    channels=3,\n",
    "    timesteps=1000,\n",
    "    beta_start=1e-4,\n",
    "    beta_end=0.02,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(diffusion.parameters(), lr=2e-4, betas=(0.9, 0.999))\n",
    "\n",
    "ema = EMA(\n",
    "    diffusion,\n",
    "    beta=0.9999,\n",
    "    update_after_step=0,\n",
    "    update_every=1,\n",
    ").to(device)\n",
    "\n",
    "is_cuda = device.type == \"cuda\"\n",
    "scaler = torch.amp.GradScaler(device.type, enabled=is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93386bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Training loop\n",
    "# ---------------------------------\n",
    "import math \n",
    "\n",
    "target_steps = 10000 #lower it based on your storage, but originally 80k\n",
    "grad_accum = 2\n",
    "\n",
    "steps_per_epoch = len(train_dl) // grad_accum\n",
    "epochs = math.ceil(target_steps / max(1, steps_per_epoch))\n",
    "\n",
    "save_dir = \"./results\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "global_step = 0\n",
    "diffusion.train()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(train_dl, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(pbar):\n",
    "        imgs, _ = batch  \n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.autocast(device_type=device.type, enabled=is_cuda):\n",
    "            loss = diffusion(imgs) / grad_accum\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % grad_accum == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(diffusion.parameters(), 1.0)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            ema.update()\n",
    "            global_step += 1\n",
    "\n",
    "        loss_item = loss.item() * grad_accum\n",
    "        avg_loss = loss_item if avg_loss == 0.0 else 0.9 * avg_loss + 0.1 * loss_item\n",
    "        pbar.set_postfix(loss=f\"{avg_loss:.4f}\", lr=f\"{optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    ckpt_path = os.path.join(save_dir, f\"model_epoch_{epoch}.pt\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"diffusion\": diffusion.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"ema\": ema.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"global_step\": global_step,\n",
    "        },\n",
    "        ckpt_path,\n",
    "    )\n",
    "    print(f\"Saved {ckpt_path} | avg_loss {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saved {ckpt_path} | avg_loss {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27702b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ema_pytorch import EMA\n",
    "from train.evaluation import FIDEvaluation\n",
    "\n",
    "# Load checkpoint (add weights_only=True once you’ve moved to PyTorch ≥2.4)\n",
    "ckpt_path = \"./results/model_epoch_37.pt\"\n",
    "print(f\"Loading checkpoint: {ckpt_path}\")\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "diffusion.load_state_dict(ckpt[\"diffusion\"])\n",
    "\n",
    "ema = EMA(\n",
    "    diffusion,\n",
    "    beta=0.9999,\n",
    "    update_after_step=0,\n",
    "    update_every=1,\n",
    ").to(device)\n",
    "if \"ema\" in ckpt:\n",
    "    ema.load_state_dict(ckpt[\"ema\"])\n",
    "\n",
    "diffusion.eval()\n",
    "ema.ema_model.eval()\n",
    "\n",
    "# Image-only wrapper so FID sees tensors, not (img,label) tuples\n",
    "class ImageOnlyLoader:\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "\n",
    "    def __iter__(self):\n",
    "        for imgs, _ in self.dataloader:\n",
    "            yield imgs\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "real_dl = ImageOnlyLoader(test_dl)\n",
    "\n",
    "class DiffusionSamplerWrapper:\n",
    "    def __init__(self, diffusion, device):\n",
    "        self.diffusion = diffusion\n",
    "        self.device = device\n",
    "\n",
    "    def eval(self):\n",
    "        self.diffusion.eval()\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def sample(self, batch_size):\n",
    "        samples = self.diffusion.sample(batch_size=batch_size)\n",
    "        return samples.to(self.device)\n",
    "\n",
    "sampler = DiffusionSamplerWrapper(diffusion=ema.ema_model, device=device)\n",
    "\n",
    "fid_eval = FIDEvaluation(\n",
    "    batch_size=256,\n",
    "    dataloader=real_dl,\n",
    "    sampler=sampler,\n",
    "    device=device,\n",
    "    channels=3,\n",
    "    num_samples=10_000,  # Ideally set it to 50k with enough time and computing power\n",
    ")\n",
    "\n",
    "print(\"Computing FID…\")\n",
    "fid_value = fid_eval.fid_score()\n",
    "print(f\"FID: {fid_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b61e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"FID: {fid_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf814684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "batch_size = 10   \n",
    "num_steps_to_show = 10  \n",
    "\n",
    "with torch.no_grad():\n",
    "    traj = diffusion.sample(batch_size=batch_size, return_all_timesteps=True)\n",
    "assert traj.dim() == 5, f\"Expected (T,B,C,H,W), got {traj.shape}\"\n",
    "\n",
    "if traj.size(0) < traj.size(1):  \n",
    "    traj = traj.permute(1, 0, 2, 3, 4).contiguous()\n",
    "\n",
    "T = traj.size(0)\n",
    "idx = torch.linspace(0, T - 1, steps=num_steps_to_show, device=traj.device).round().long()\n",
    "idx = torch.unique_consecutive(idx)  \n",
    "traj = traj.index_select(0, idx)     \n",
    "k = traj.size(0)\n",
    "\n",
    "traj = (traj + 1) / 2\n",
    "traj = traj.clamp(0, 1)\n",
    "\n",
    "_, B, C, H, W = traj.shape\n",
    "flat = traj.permute(1, 0, 2, 3, 4).contiguous().view(B * k, C, H, W)\n",
    "grid = make_grid(flat, nrow=k, padding=2)\n",
    "\n",
    "save_image(grid.cpu(), f'generated.png')\n",
    "print(f\"Saved panel with {B} rows × {k} columns (10×10).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61660ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "generated_png = \"/content/drive/MyDrive/ddpm_pytorch/generated.png\"\n",
    "Image(generated_png, width=800)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
